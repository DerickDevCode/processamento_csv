# Processamento de arquivos CSV com t√©cnicas em lote

Projeto que compara a efici√™ncia de diferentes t√©cnicas de processamento de arquivos csv para banco de dados.

<h2 id="tech">üíª Tecnologias</h2>

- Python
- Git
- Poetry
- Docker
- PostgreSQL
- Celery

## passo a passo para rodar o projeto.

- Clone o projeto localmente com o comando:
  ```bash
  git clone https://github.com/DerickDevCode/processamento_csv.git
  ```

- Instale as depend√™ncias usando poetry com o comando:
  ```bash
  poetry install
  ```

- Crie o seu arquivo .env e defina as vari√°veis de ambiente baseadas no arquivo env-sample:
  ```yaml
  POSTGRES_PASSWORD=defina sua senha do banco de dados aqui
  POSTGRES_USER=defina seu usu√°rio do banco de dados aqui
  POSTGRES_DB=defina o nome do seu banco de dados aqui
  ```

- Ap√≥s definir as vari√°veis de ambiente do Postgres acima, Suba um banco Postgresql e um Rabbitmq usando o
  docker-compose.yml:
  ```bash
  docker compose up
  ```

Agora voc√™ tem o projeto pronto para ser usado no seu computador.

Para gerar os arquivos com os dados para serem processados use o [criar_arquivos_csv.py](criar_arquivos_csv.py).

Os arquivos para configurar o processamento dos dados de forma s√≠ncrona s√£o:

- [processar_dados_um_por_um.py](processar_dados_um_por_um.py)
- [processar_dados_em_lote.py](processar_dados_em_lote.py)
- [processar_dados_dois_arquivos_por_vez.py](processar_dados_dois_arquivos_por_vez.py)

As tasks para fazer o processamento ass√≠ncrono dos arquivos se encontram em [tasks.py](tasks.py) e voc√™ pode execut√°-las
rodando o arquivo [run_tasks.py](run_tasks.py)